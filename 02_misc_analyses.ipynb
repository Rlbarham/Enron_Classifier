{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Enron 'person of interest' classifier: Miscellaneous analyses</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is used to perform a variety of analyses on the Enron data, in order to a) explore the data and b) experiment with the classifiers, features included, and other aspects of the classifier algorithm to optimize our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Data exploration</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I attempt to understand the size and character of the data, and uncover some basic information about its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type used for base data: dict\n",
      "Number of rows in the data set: 146\n",
      "Number of POIs present: 18\n",
      "Number of non-POIs present: 128\n",
      "\n",
      "\n",
      "Feature: salary; 65% coverage\n",
      "Feature: to_messages; 59% coverage\n",
      "Feature: deferral_payments; 27% coverage\n",
      "Feature: total_payments; 86% coverage\n",
      "Feature: exercised_stock_options; 70% coverage\n",
      "Feature: bonus; 56% coverage\n",
      "Feature: restricted_stock; 75% coverage\n",
      "Feature: shared_receipt_with_poi; 59% coverage\n",
      "Feature: restricted_stock_deferred; 12% coverage\n",
      "Feature: total_stock_value; 86% coverage\n",
      "Feature: expenses; 65% coverage\n",
      "Feature: loan_advances; 3% coverage\n",
      "Feature: from_messages; 59% coverage\n",
      "Feature: other; 64% coverage\n",
      "Feature: from_this_person_to_poi; 59% coverage\n",
      "Feature: poi; 100% coverage\n",
      "Feature: director_fees; 12% coverage\n",
      "Feature: deferred_income; 34% coverage\n",
      "Feature: long_term_incentive; 45% coverage\n",
      "Feature: email_address; 76% coverage\n",
      "Feature: from_poi_to_this_person; 59% coverage\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "enron_data = pickle.load(open(\"final_project_dataset.pkl\", \"r\"))\n",
    "\n",
    "# Print the data type\n",
    "print \"Data type used for base data: %s\" % type(enron_data).__name__\n",
    "\n",
    "# Print the length of the data set\n",
    "print \"Number of rows in the data set: %s\" % len(enron_data)\n",
    "  \n",
    "# Check how many POIs versus non-POIs are in the data\n",
    "poi_count = 0\n",
    "non_poi_count = 0\n",
    "\n",
    "for key in enron_data:\n",
    "    if enron_data[key]['poi'] == True:\n",
    "        poi_count += 1\n",
    "    elif enron_data[key]['poi'] == False:\n",
    "        non_poi_count += 1\n",
    "\n",
    "print \"Number of POIs present: %s\" % poi_count\n",
    "print\"Number of non-POIs present: %s\" % non_poi_count\n",
    "print \"\\n\"\n",
    "\n",
    "# Print list of features and percentage of records each covers\n",
    "for internal_key in enron_data['METTS MARK']:\n",
    "    nan_count = 0\n",
    "    non_nan = 0\n",
    "    \n",
    "    for m in enron_data.iteritems():\n",
    "        if m[1][internal_key] == 'NaN':\n",
    "            nan_count += 1\n",
    "        else:\n",
    "            non_nan += 1\n",
    "    print \"Feature: %s; %s coverage\" %(internal_key,\\\n",
    "                    '{0:.0%}'.format(1 - nan_count/146.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Outlier detection</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I attempt to detect and (where appropriate) remove outliers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "data_dict = pickle.load( open(\"final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "# Code to remove Total; comment the line to re-run first figure\n",
    "# data_dict.pop( 'TOTAL', 0 )\n",
    "\n",
    "# Print and optionally save figure of total stock v total payments\n",
    "features = [\"total_payments\", \"total_stock_value\"]\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "for point in data:\n",
    "    payments = point[0]\n",
    "    stock = point[1]\n",
    "    matplotlib.pyplot.scatter( payments, stock )\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"total payments\")\n",
    "matplotlib.pyplot.ylabel(\"total stock value\")\n",
    "# matplotlib.pyplot.savefig('./images/fig_02.png', dpi=300)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309886585.0\n",
      "TOTAL\n"
     ]
    }
   ],
   "source": [
    "# Print out the outlier with the highest total payments\n",
    "payments_test = data.max(axis=0)[0]\n",
    "for m in data_dict.iteritems():\n",
    "    if m[1]['total_payments'] == payments_test:\n",
    "        print payments_test\n",
    "        print m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309886585.0\n",
      "ndarray\n",
      "434509511.0\n",
      "None\n",
      "LAY KENNETH L\n",
      "FREVERT MARK A\n",
      "BHATNAGAR SANJAY\n",
      "LAVORATO JOHN J\n",
      "SKILLING JEFFREY K\n",
      "MARTIN AMANDA K\n",
      "BAXTER JOHN C\n",
      "BELDEN TIMOTHY N\n",
      "DELAINEY DAVID W\n",
      "WHALLEY LAWRENCE G\n",
      "[[  1.03559793e+08   4.91100780e+07]\n",
      " [  1.72525300e+07   3.07660640e+07]\n",
      " [  1.54562900e+07   2.60936720e+07]\n",
      " [  1.04257570e+07   2.38179300e+07]\n",
      " [  8.68271600e+06   2.25425390e+07]\n",
      " [  8.40701600e+06   1.51441230e+07]\n",
      " [  5.63434300e+06   1.46221850e+07]\n",
      " [  5.50163000e+06   1.18847580e+07]\n",
      " [  4.74797900e+06   1.06232580e+07]\n",
      " [  4.67757400e+06   8.83191300e+06]]\n",
      "LAY KENNETH L\n",
      "HIRKO JOSEPH\n",
      "SKILLING JEFFREY K\n",
      "PAI LOU L\n",
      "RICE KENNETH D\n",
      "WHITE JR THOMAS E\n",
      "FREVERT MARK A\n",
      "YEAGER F SCOTT\n",
      "BAXTER JOHN C\n",
      "DERRICK JR. JAMES V\n"
     ]
    }
   ],
   "source": [
    "# Explore whether there are further payments / stock outliers\n",
    "# by printing information on highest figures\n",
    "\n",
    "print data.max(axis=0)[0]\n",
    "print type(data).__name__\n",
    "print data.max(axis=0)[1]\n",
    "print data.sort(axis=0)\n",
    "\n",
    "# Return the top 10 highest paid execs still in the data\n",
    "sorted_by_salary = data[data[:, 0].argsort()][::-1][1:11]\n",
    "\n",
    "# Print the names of each of the top 10\n",
    "for value in sorted_by_salary[:, [0]]:\n",
    "    for m in data_dict.iteritems():\n",
    "        if m[1]['total_payments'] == value[0]:\n",
    "            print m[0]\n",
    "            \n",
    "# Return the top 10 highest stock execs still in the data\n",
    "sorted_by_stock = data[data[:, 0].argsort()][::-1][1:11]\n",
    "print sorted_by_stock\n",
    "\n",
    "# Print the names of each of the top 10\n",
    "for value in sorted_by_salary[:, [1]]:\n",
    "    for m in data_dict.iteritems():\n",
    "        if m[1]['total_stock_value'] == value[0]:\n",
    "            print m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Detecting email outliers\n",
    "data_dict = pickle.load( open(\"final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "# Code to remove Total; uncomment to re-run first figure\n",
    "data_dict.pop( 'TOTAL', 0 )\n",
    "\n",
    "# Print and optionally save figure \n",
    "features = [\"to_messages\", \"from_messages\"]\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "for point in data:\n",
    "    to_messages = point[0]\n",
    "    from_messages = point[1]\n",
    "    matplotlib.pyplot.scatter( to_messages, from_messages )\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"to_messages\")\n",
    "matplotlib.pyplot.ylabel(\"from_messages\")\n",
    "# matplotlib.pyplot.savefig('./images/fig_03.png', dpi=300)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPIRO RICHARD S\n",
      "KEAN STEVEN J\n",
      "KITCHEN LOUISE\n",
      "BELDEN TIMOTHY N\n",
      "BECK SALLY W\n",
      "LAVORATO JOHN J\n",
      "WHALLEY LAWRENCE G\n",
      "KAMINSKI WINCENTY J\n",
      "LAY KENNETH L\n",
      "HAEDICKE MARK E\n"
     ]
    }
   ],
   "source": [
    "# Return the top 10 highest to_emails\n",
    "sorted_by_email = data[data[:, 0].argsort()][::-1][0:10]\n",
    "\n",
    "# Print the names of each of the top 10\n",
    "for value in sorted_by_email[:, [0]]:\n",
    "    for m in data_dict.iteritems():\n",
    "        if m[1]['to_messages'] == value[0]:\n",
    "            print m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Detecting email outliers to/from POIs\n",
    "\n",
    "data_dict = pickle.load( open(\"final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "# Code to remove Total; uncomment to re-run first figure\n",
    "data_dict.pop( 'TOTAL', 0 )\n",
    "\n",
    "# Print and optionally save figure \n",
    "features = [\"from_this_person_to_poi\", \"from_poi_to_this_person\"]\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "for point in data:\n",
    "    to_messages = point[0]\n",
    "    from_messages = point[1]\n",
    "    matplotlib.pyplot.scatter( to_messages, from_messages )\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"to__poi_messages\")\n",
    "matplotlib.pyplot.ylabel(\"from__poi_messages\")\n",
    "# matplotlib.pyplot.savefig('./images/fig_04.png', dpi=300)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELAINEY DAVID W\n",
      "LAVORATO JOHN J\n",
      "KEAN STEVEN J\n",
      "BECK SALLY W\n",
      "KITCHEN LOUISE\n",
      "MCCONNELL MICHAEL S\n",
      "KITCHEN LOUISE\n",
      "MCCONNELL MICHAEL S\n",
      "KAMINSKI WINCENTY J\n",
      "BELDEN TIMOTHY N\n",
      "SHANKMAN JEFFREY A\n",
      "BUY RICHARD B\n"
     ]
    }
   ],
   "source": [
    "# Return the top 10 highest to_poi_emails\n",
    "sorted_by_poi_email = data[data[:, 0].argsort()][::-1][0:10]\n",
    "\n",
    "# Print the names of each of the top 10\n",
    "for value in sorted_by_poi_email[:, [0]]:\n",
    "    for m in data_dict.iteritems():\n",
    "        if m[1]['from_this_person_to_poi'] == value[0]:\n",
    "            print m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAXTER JOHN C\n",
      "ELLIOTT STEVEN\n",
      "MORDAUNT KRISTINA M\n",
      "LOWRY CHARLES P\n",
      "WESTFAHL RICHARD K\n",
      "WALTERS GARETH W\n",
      "CHAN RONNIE\n",
      "BELFER ROBERT\n",
      "WODRASKA JOHN\n",
      "URQUHART JOHN A\n",
      "WHALEY DAVID A\n",
      "ECHOLS JOHN B\n",
      "MENDELSOHN JOHN\n",
      "CLINE KENNETH W\n",
      "KOPPER MICHAEL J\n",
      "BERBERIAN DAVID\n",
      "DETMERING TIMOTHY J\n",
      "WAKEHAM JOHN\n",
      "GOLD JOSEPH\n",
      "DUNCAN JOHN H\n",
      "LEMAISTRE CHARLES\n",
      "KISHKILL JOSEPH G\n",
      "SULLIVAN-SHAKLOVITZ COLLEEN\n",
      "WROBEL BRUCE\n",
      "LINDHOLM TOD A\n",
      "MEYER JEROME J\n",
      "BUTTS ROBERT H\n",
      "CUMBERLAND MICHAEL S\n",
      "GAHN ROBERT S\n",
      "HERMANN ROBERT J\n",
      "SCRIMSHAW MATTHEW\n",
      "GATHMANN WILLIAM D\n",
      "GILLIS JOHN\n",
      "BAZELIDES PHILIP J\n",
      "FASTOW ANDREW S\n",
      "LOCKHART EUGENE E\n",
      "OVERDYKE JR JERE C\n",
      "PEREIRA PAULO V. FERRAZ\n",
      "STABLER FRANK\n",
      "BLAKE JR. NORMAN P\n",
      "PRENTICE JAMES\n",
      "GRAY RODNEY\n",
      "THE TRAVEL AGENCY IN THE PARK\n",
      "NOLES JAMES L\n",
      "WHITE JR THOMAS E\n",
      "CHRISTODOULOU DIOMEDES\n",
      "JAEDICKE ROBERT\n",
      "WINOKUR JR. HERBERT S\n",
      "BADUM JAMES P\n",
      "REYNOLDS LAWRENCE\n",
      "DIMICHELE RICHARD G\n",
      "YEAP SOON\n",
      "YEAGER F SCOTT\n",
      "HIRKO JOSEPH\n",
      "PAI LOU L\n",
      "BAY FRANKLIN R\n",
      "FUGH JOHN L\n",
      "SAVAGE FRANK\n",
      "GRAMM WENDY L\n"
     ]
    }
   ],
   "source": [
    "# Print individuals with no email activity\n",
    "\n",
    "for m in data_dict.iteritems():\n",
    "    if m[1]['to_messages'] == 'NaN':\n",
    "        print m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOWRY CHARLES P\n",
      "{'salary': 'NaN', 'to_messages': 'NaN', 'deferral_payments': 'NaN', 'total_payments': 'NaN', 'exercised_stock_options': 372205, 'bonus': 'NaN', 'restricted_stock': 153686, 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': -153686, 'total_stock_value': 372205, 'expenses': 'NaN', 'loan_advances': 'NaN', 'from_messages': 'NaN', 'other': 'NaN', 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 'NaN', 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n",
      "\n",
      "\n",
      "CHAN RONNIE\n",
      "{'salary': 'NaN', 'to_messages': 'NaN', 'deferral_payments': 'NaN', 'total_payments': 'NaN', 'exercised_stock_options': 'NaN', 'bonus': 'NaN', 'restricted_stock': 32460, 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': -32460, 'total_stock_value': 'NaN', 'expenses': 'NaN', 'loan_advances': 'NaN', 'from_messages': 'NaN', 'other': 'NaN', 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 98784, 'deferred_income': -98784, 'long_term_incentive': 'NaN', 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n",
      "\n",
      "\n",
      "WHALEY DAVID A\n",
      "{'salary': 'NaN', 'to_messages': 'NaN', 'deferral_payments': 'NaN', 'total_payments': 'NaN', 'exercised_stock_options': 98718, 'bonus': 'NaN', 'restricted_stock': 'NaN', 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': 'NaN', 'total_stock_value': 98718, 'expenses': 'NaN', 'loan_advances': 'NaN', 'from_messages': 'NaN', 'other': 'NaN', 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 'NaN', 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n",
      "\n",
      "\n",
      "CLINE KENNETH W\n",
      "{'salary': 'NaN', 'to_messages': 'NaN', 'deferral_payments': 'NaN', 'total_payments': 'NaN', 'exercised_stock_options': 'NaN', 'bonus': 'NaN', 'restricted_stock': 662086, 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': -472568, 'total_stock_value': 189518, 'expenses': 'NaN', 'loan_advances': 'NaN', 'from_messages': 'NaN', 'other': 'NaN', 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 'NaN', 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n",
      "\n",
      "\n",
      "WROBEL BRUCE\n",
      "{'salary': 'NaN', 'to_messages': 'NaN', 'deferral_payments': 'NaN', 'total_payments': 'NaN', 'exercised_stock_options': 139130, 'bonus': 'NaN', 'restricted_stock': 'NaN', 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': 'NaN', 'total_stock_value': 139130, 'expenses': 'NaN', 'loan_advances': 'NaN', 'from_messages': 'NaN', 'other': 'NaN', 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 'NaN', 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n",
      "\n",
      "\n",
      "SCRIMSHAW MATTHEW\n",
      "{'salary': 'NaN', 'to_messages': 'NaN', 'deferral_payments': 'NaN', 'total_payments': 'NaN', 'exercised_stock_options': 759557, 'bonus': 'NaN', 'restricted_stock': 'NaN', 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': 'NaN', 'total_stock_value': 759557, 'expenses': 'NaN', 'loan_advances': 'NaN', 'from_messages': 'NaN', 'other': 'NaN', 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 'NaN', 'email_address': 'matthew.scrimshaw@enron.com', 'from_poi_to_this_person': 'NaN'}\n",
      "\n",
      "\n",
      "GATHMANN WILLIAM D\n",
      "{'salary': 'NaN', 'to_messages': 'NaN', 'deferral_payments': 'NaN', 'total_payments': 'NaN', 'exercised_stock_options': 1753766, 'bonus': 'NaN', 'restricted_stock': 264013, 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': -72419, 'total_stock_value': 1945360, 'expenses': 'NaN', 'loan_advances': 'NaN', 'from_messages': 'NaN', 'other': 'NaN', 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 'NaN', 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n",
      "\n",
      "\n",
      "GILLIS JOHN\n",
      "{'salary': 'NaN', 'to_messages': 'NaN', 'deferral_payments': 'NaN', 'total_payments': 'NaN', 'exercised_stock_options': 9803, 'bonus': 'NaN', 'restricted_stock': 75838, 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': 'NaN', 'total_stock_value': 85641, 'expenses': 'NaN', 'loan_advances': 'NaN', 'from_messages': 'NaN', 'other': 'NaN', 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 'NaN', 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n",
      "\n",
      "\n",
      "LOCKHART EUGENE E\n",
      "{'salary': 'NaN', 'to_messages': 'NaN', 'deferral_payments': 'NaN', 'total_payments': 'NaN', 'exercised_stock_options': 'NaN', 'bonus': 'NaN', 'restricted_stock': 'NaN', 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': 'NaN', 'total_stock_value': 'NaN', 'expenses': 'NaN', 'loan_advances': 'NaN', 'from_messages': 'NaN', 'other': 'NaN', 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 'NaN', 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n",
      "\n",
      "\n",
      "CHRISTODOULOU DIOMEDES\n",
      "{'salary': 'NaN', 'to_messages': 'NaN', 'deferral_payments': 'NaN', 'total_payments': 'NaN', 'exercised_stock_options': 5127155, 'bonus': 'NaN', 'restricted_stock': 950730, 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': 'NaN', 'total_stock_value': 6077885, 'expenses': 'NaN', 'loan_advances': 'NaN', 'from_messages': 'NaN', 'other': 'NaN', 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 'NaN', 'email_address': 'diomedes.christodoulou@enron.com', 'from_poi_to_this_person': 'NaN'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print suspected empty records; manually confirm if any fully empty\n",
    "\n",
    "for m in data_dict.iteritems():\n",
    "    if m[1]['to_messages'] == 'NaN' and m[1]['total_payments'] == 'NaN':\n",
    "        print m[0]\n",
    "        print data_dict[m[0]]\n",
    "        print \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    }
   ],
   "source": [
    "# Remove remaining outliers\n",
    "\n",
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK', 0)\n",
    "data_dict.pop('LOCKHART EUGENE E', 0)\n",
    "\n",
    "print len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Features</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I evaluate the features in the data, ensure any that are clearly not of use are removed, and create new features as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature evaluation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bonus', 30.728774633399713), ('salary', 15.858730905995131), ('shared_receipt_with_poi', 10.722570813682712), ('total_stock_value', 10.633852048382538), ('exercised_stock_options', 9.6800414303809852), ('total_payments', 8.9591366476908583), ('deferred_income', 8.7922038527047608), ('restricted_stock', 8.058306312280525), ('long_term_incentive', 7.5551197773202938), ('loan_advances', 7.0379327981934612), ('from_poi_to_this_person', 4.9586666839661424), ('expenses', 4.1807214846470577), ('other', 3.2044591402721507), ('to_messages', 2.6161830046793662), ('director_fees', 1.6410979261701475), ('restricted_stock_deferred', 0.72712410971776964), ('from_messages', 0.43537409865824717), ('from_this_person_to_poi', 0.11120823866694469), ('deferral_payments', 0.0099823995896919059)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Import features for analysis\n",
    "features_list = ['poi', 'salary', 'to_messages', 'deferral_payments', \n",
    "                 'total_payments','exercised_stock_options', 'bonus', \n",
    "                 'restricted_stock', 'shared_receipt_with_poi',\n",
    "                 'restricted_stock_deferred', 'total_stock_value', \n",
    "                 'expenses','loan_advances','from_messages', 'other', \n",
    "                 'from_this_person_to_poi','director_fees', \n",
    "                 'deferred_income','long_term_incentive', \n",
    "                 'from_poi_to_this_person']\n",
    "\n",
    "data = featureFormat(data_dict, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Perform K-best analysis\n",
    "k_best = SelectKBest(k='all')\n",
    "k_best.fit(features_train, labels_train)\n",
    "features_unsorted = zip(features_list[1:], k_best.scores_)\n",
    "features_sorted = sorted(features_unsorted, key=lambda tup: tup[1],\\\n",
    "                         reverse=True)\n",
    "\n",
    "print features_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>New features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bonus', 30.728774633399713), ('salary', 15.858730905995131), ('to_poi_proportion', 15.838094949193755), ('shared_receipt_with_poi', 10.722570813682712), ('total_stock_value', 10.633852048382538), ('exercised_stock_options', 9.6800414303809852), ('total_payments', 8.9591366476908583), ('deferred_income', 8.7922038527047608), ('restricted_stock', 8.058306312280525), ('long_term_incentive', 7.5551197773202938), ('loan_advances', 7.0379327981934612), ('from_poi_to_this_person', 4.9586666839661424), ('expenses', 4.1807214846470577), ('other', 3.2044591402721507), ('to_messages', 2.6161830046793662), ('director_fees', 1.6410979261701475), ('restricted_stock_deferred', 0.72712410971776964), ('from_poi_proportion', 0.51923116954782722), ('from_messages', 0.43537409865824717), ('from_this_person_to_poi', 0.11120823866694469), ('deferral_payments', 0.0099823995896919059)]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pickle\n",
    "    \n",
    "# Basic fraction computation function\n",
    "def computeFraction( poi_messages, all_messages ):\n",
    "    \"\"\" given a number messages to/from POI (numerator) \n",
    "        and number of all messages to/from a person (denominator),\n",
    "        return the fraction of messages to/from that person\n",
    "        that are from/to a POI\n",
    "   \"\"\"    \n",
    "    if poi_messages == 'NaN' or all_messages == 'NaN':\n",
    "        return 0\n",
    "    else:\n",
    "        fraction = poi_messages/all_messages\n",
    "        return fraction\n",
    "    \n",
    "# Compute from_poi_proportion and to_poi_proportion using computeFraction function\n",
    "submit_dict = {}\n",
    "for name in data_dict:\n",
    "    data_point = data_dict[name]\n",
    "    \n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
    "    to_messages = data_point[\"to_messages\"]\n",
    "    from_poi_proportion = computeFraction( from_poi_to_this_person, to_messages )\n",
    "    data_point[\"from_poi_proportion\"] = from_poi_proportion\n",
    "\n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
    "    from_messages = data_point[\"from_messages\"]\n",
    "    to_poi_proportion = computeFraction( from_this_person_to_poi, from_messages )\n",
    "    data_point[\"to_poi_proportion\"] = to_poi_proportion\n",
    "    \n",
    "\n",
    "# Re-run the K-Best evaluation with new features included\n",
    "\n",
    "# Import features for analysis\n",
    "features_list = ['poi', 'salary', 'to_messages', 'deferral_payments', \n",
    "                 'total_payments','exercised_stock_options', 'bonus',\n",
    "                 'restricted_stock', 'shared_receipt_with_poi',\n",
    "                 'restricted_stock_deferred', 'total_stock_value',\n",
    "                 'expenses', 'loan_advances', 'from_messages', 'other',\n",
    "                 'from_this_person_to_poi','director_fees',\n",
    "                 'deferred_income', 'long_term_incentive', \n",
    "                 'from_poi_to_this_person', 'from_poi_proportion',\n",
    "                 'to_poi_proportion']\n",
    "\n",
    "data = featureFormat(data_dict, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Perform K-best analysis\n",
    "k_best = SelectKBest(k='all')\n",
    "k_best.fit(features_train, labels_train)\n",
    "features_unsorted = zip(features_list[1:], k_best.scores_)\n",
    "features_sorted = sorted(features_unsorted, key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "print features_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature scaling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Import features for analysis\n",
    "features_list = ['poi', 'salary', 'to_messages', 'deferral_payments', \n",
    "                 'total_payments','exercised_stock_options', 'bonus',\n",
    "                 'restricted_stock', 'shared_receipt_with_poi',\n",
    "                 'restricted_stock_deferred', 'total_stock_value',\n",
    "                 'expenses', 'loan_advances', 'from_messages', 'other',\n",
    "                 'from_this_person_to_poi','director_fees',\n",
    "                 'deferred_income', 'long_term_incentive', \n",
    "                 'from_poi_to_this_person', 'from_poi_proportion',\n",
    "                 'to_poi_proportion']\n",
    "\n",
    "#  Initialize scaler, fit and transform the data with it\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluation metrics</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I create some basic evaluation metrics on which to assess classifiers and any 'fine tuning' we go on to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import relevant modules\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,\\\n",
    "accuracy_score\n",
    "\n",
    "# Create function to test a classifier on each evaluation metric\n",
    "def classifier_evaluation(truth, prediction):\n",
    "    confusion_matrix = Counter()\n",
    "    positives = [1]\n",
    "    \n",
    "    truth_split = [i in positives for i in truth]\n",
    "    prediction_split = [i in positives for i in prediction]\n",
    "    for x, y in zip(truth_split, prediction_split):\n",
    "        confusion_matrix[x,y] += 1\n",
    "   \n",
    "    print confusion_matrix\n",
    "    print \"Accuracy: \", accuracy_score(truth, prediction)\n",
    "    print \"Precision Score: \", precision_score(truth, prediction)\n",
    "    print \"Recall Score: \", recall_score(truth, prediction)\n",
    "    print \"F1 Score: \", f1_score(truth, prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classifiers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I select, test, and fine-tune classifiers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Initial classifier test</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Naive Bayes classifier:\n",
      "Counter({(False, True): 27, (False, False): 11, (True, True): 4, (True, False): 1})\n",
      "Accuracy:  0.348837209302\n",
      "Precision Score:  0.129032258065\n",
      "Recall Score:  0.8\n",
      "F1 Score:  0.222222222222\n",
      "None\n",
      "\n",
      "\n",
      "---> Logistic regression:\n",
      "Counter({(False, False): 31, (False, True): 7, (True, False): 4, (True, True): 1})\n",
      "Accuracy:  0.744186046512\n",
      "Precision Score:  0.125\n",
      "Recall Score:  0.2\n",
      "F1 Score:  0.153846153846\n",
      "None\n",
      "\n",
      "\n",
      "---> SVM classifier:\n",
      "Counter({(False, False): 38, (True, False): 5})\n",
      "Accuracy:  0.883720930233\n",
      "Precision Score:  0.0\n",
      "Recall Score:  0.0\n",
      "F1 Score:  0.0\n",
      "None\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rob/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rob/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" NB: My goal in this section to try out a large number of \n",
    "    classifiers and to get a sense of which seem strongest\n",
    "    based on minimal fine-tuning. I'll select the highest-\n",
    "    performing two algorithms to refine and improve\"\"\"\n",
    "\n",
    "# Naive Bayes test\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB_classifier = GaussianNB()\n",
    "NB_classifier.fit(features_train, labels_train)\n",
    "labels_pred = NB_classifier.predict(features_test)\n",
    "print \"---> Naive Bayes classifier:\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\"\n",
    "\n",
    "# Logistic regression test\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lreg_classifier = LogisticRegression(C=1000)\n",
    "lreg_classifier.fit(features_train, labels_train)\n",
    "labels_pred = lreg_classifier.predict(features_test)\n",
    "print \"---> Logistic regression:\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\"\n",
    "\n",
    "# SVM test\n",
    "from sklearn import svm\n",
    "svm_classifier = svm.SVC(C=1000)\n",
    "svm_classifier.fit(features_train, labels_train)\n",
    "labels_pred = svm_classifier.predict(features_test)\n",
    "print \"---> SVM classifier:\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tuning: SVM</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# SVM test: initial\n",
    "from sklearn import svm\n",
    "svm_classifier = svm.SVC(C=1000)\n",
    "svm_classifier.fit(features_train, labels_train)\n",
    "labels_pred = svm_classifier.predict(features_test)\n",
    "print \"---> Initial SVM classifier:\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\"\n",
    "\n",
    "# SVM tuning: GridSearch\n",
    "scorer = make_scorer(f1_score)\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), \\\n",
    "              'C':[1, 10, 100, 500, 1000, 1100, 1200, 1300, 1400, 1500, 1600 ], \\\n",
    "             'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]}\n",
    "svr = svm.SVC()\n",
    "svm_tuning = GridSearchCV(svr, parameters, scoring=scorer, verbose=1)\n",
    "svm_tuning.fit(features_train, labels_train)\n",
    "\n",
    "print svm_tuning.best_estimator_\n",
    "# print svm_tuning.best_params_\n",
    "print \"\\n\"\n",
    "\n",
    "# SVM test: gridsearch-tuned \n",
    "svm_classifier = svm.SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
    "  gamma=0.05, kernel='rbf', max_iter=-1, probability=False,\n",
    "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "svm_classifier.fit(features_train, labels_train)\n",
    "labels_pred = svm_classifier.predict(features_test)\n",
    "print \"---> Gridsearch-tuned SVM classifier:\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\"\n",
    "\n",
    "# Legacy manually tweaked classifier\n",
    "# svm_classifier = svm.SVC(C=1600, kernel='rbf', gamma=0.05)\n",
    "# svm_classifier.fit(features_train, labels_train)\n",
    "# labels_pred = svm_classifier.predict(features_test)\n",
    "# print \"---> SVM classifier:\"\n",
    "# print classifier_evaluation(labels_test, labels_pred)\n",
    "# print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tuning: Logistic regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Logistic regression:\n",
      "Counter({(False, False): 31, (False, True): 7, (True, False): 4, (True, True): 1})\n",
      "Accuracy:  0.744186046512\n",
      "Precision Score:  0.125\n",
      "Recall Score:  0.2\n",
      "F1 Score:  0.153846153846\n",
      "None\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "LogisticRegression(C=1, class_weight='auto', dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=1e-05,\n",
      "          verbose=0)\n",
      "\n",
      "\n",
      "---> Logistic regression: Gridsearch tuned\n",
      "Counter({(False, True): 20, (False, False): 18, (True, True): 3, (True, False): 2})\n",
      "Accuracy:  0.488372093023\n",
      "Precision Score:  0.130434782609\n",
      "Recall Score:  0.6\n",
      "F1 Score:  0.214285714286\n",
      "None\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Logistic regression: initial algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lreg_classifier = LogisticRegression(C=1000)\n",
    "lreg_classifier.fit(features_train, labels_train)\n",
    "labels_pred = lreg_classifier.predict(features_test)\n",
    "print \"---> Logistic regression:\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\"\n",
    "\n",
    "# Logistic regression tuning: GridSearch\n",
    "scorer = make_scorer(f1_score)\n",
    "parameters = {\"C\":[0.05, 0.5, 1, 10, 100,500,1000,10000,100000, 1000000],\n",
    "                    \"tol\":[10**-1, 10**-5, 10**-10],\n",
    "                    \"class_weight\":['auto']}\n",
    "lreg_classifier = LogisticRegression()\n",
    "lreg_tuning = GridSearchCV(lreg_classifier, parameters, scoring=scorer, verbose=1)\n",
    "lreg_tuning.fit(features_train, labels_train)\n",
    "\n",
    "print lreg_tuning.best_estimator_\n",
    "# print lreg_tuning.best_params_\n",
    "print \"\\n\"\n",
    "\n",
    "# Logistic regression: Gridsearch-tuned\n",
    "lreg_classifier = LogisticRegression(C=0.05, class_weight='auto', dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.1, verbose=0)\n",
    "lreg_classifier.fit(features_train, labels_train)\n",
    "labels_pred = lreg_classifier.predict(features_test)\n",
    "print \"---> Logistic regression: Gridsearch tuned\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Naive Bayes recap</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Naive Bayes classifier (Gaussian):\n",
      "Counter({(False, False): 35, (False, True): 3, (True, False): 3, (True, True): 2})\n",
      "Accuracy:  0.860465116279\n",
      "Precision Score:  0.4\n",
      "Recall Score:  0.4\n",
      "F1 Score:  0.4\n",
      "None\n",
      "\n",
      "\n",
      "---> Naive Bayes classifier (Multinomial):\n",
      "Counter({(False, False): 38, (True, False): 5})\n",
      "Accuracy:  0.883720930233\n",
      "Precision Score:  0.0\n",
      "Recall Score:  0.0\n",
      "F1 Score:  0.0\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes: initial algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB_classifier = GaussianNB()\n",
    "NB_classifier.fit(features_train, labels_train)\n",
    "labels_pred = NB_classifier.predict(features_test)\n",
    "print \"---> Naive Bayes classifier (Gaussian):\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\"\n",
    "\n",
    "# Multinomial Naive Bayes test\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_classifier = MultinomialNB()\n",
    "NB_classifier.fit(features_train, labels_train)\n",
    "labels_pred = NB_classifier.predict(features_test)\n",
    "print \"---> Naive Bayes classifier (Multinomial):\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Additional feature removal</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I wanted to revisit a topic from earlier, and attempt to explore whether removing features impaired performance of the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 200 jobs       | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 450 jobs       | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 800 jobs       | elapsed:    2.7s\n",
      "[Parallel(n_jobs=1)]: Done 924 out of 924 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 308 candidates, totalling 924 fits\n",
      "SVC(C=1200, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.01, kernel='sigmoid', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---> Gridsearch-tuned SVM classifier:\n",
      "Counter({(False, False): 36, (True, False): 4, (False, True): 2, (True, True): 1})\n",
      "Accuracy:  0.860465116279\n",
      "Precision Score:  0.333333333333\n",
      "Recall Score:  0.2\n",
      "F1 Score:  0.25\n",
      "None\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "LogisticRegression(C=0.05, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.1, verbose=0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---> Logistic regression: Gridsearch tuned\n",
      "Counter({(False, False): 29, (False, True): 9, (True, True): 4, (True, False): 1})\n",
      "Accuracy:  0.767441860465\n",
      "Precision Score:  0.307692307692\n",
      "Recall Score:  0.8\n",
      "F1 Score:  0.444444444444\n",
      "None\n",
      "\n",
      "\n",
      "---> Naive Bayes classifier:\n",
      "Counter({(False, False): 35, (False, True): 3, (True, False): 3, (True, True): 2})\n",
      "Accuracy:  0.860465116279\n",
      "Precision Score:  0.4\n",
      "Recall Score:  0.4\n",
      "F1 Score:  0.4\n",
      "None\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "MultinomialNB(alpha=0.1, class_prior=None, fit_prior='True')\n",
      "\n",
      "\n",
      "---> Naive Bayes multinomial: Gridsearch tuned\n",
      "Counter({(False, False): 36, (True, True): 3, (False, True): 2, (True, False): 2})\n",
      "Accuracy:  0.906976744186\n",
      "Precision Score:  0.6\n",
      "Recall Score:  0.6\n",
      "F1 Score:  0.6\n",
      "None\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Here my objective is to make a number of additional tweaks to\n",
    "# try and improve the scores we're getting here. \n",
    "\n",
    "# Feature removal, to leave 12, those at >5 score by K-best\n",
    "\n",
    "features_list = ['poi', 'salary','total_payments',\n",
    "\t'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi',\n",
    "\t'total_stock_value', 'loan_advances', 'expenses','from_poi_to_this_person',\n",
    "\t'deferred_income', 'long_term_incentive', 'to_poi_proportion']\n",
    "\n",
    "#  Initialize scaler, fit and transform the data with it\n",
    "data = featureFormat(data_dict, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "### Run tests\n",
    "\n",
    "# SVM tuning: GridSearch\n",
    "scorer = make_scorer(f1_score)\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), \\\n",
    "              'C':[1, 10, 100, 500, 1000, 1100, 1200, 1300, 1400, 1500, 1600 ], \\\n",
    "             'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]}\n",
    "svr = svm.SVC()\n",
    "svm_tuning = GridSearchCV(svr, parameters, scoring=scorer, verbose=1)\n",
    "svm_tuning.fit(features_train, labels_train)\n",
    "\n",
    "print svm_tuning.best_estimator_\n",
    "# print svm_tuning.best_params_\n",
    "print \"\\n\"\n",
    "\n",
    "# SVM test: gridsearch-tuned \n",
    "from sklearn import svm\n",
    "svm_classifier = svm.SVC(C=1200, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
    "  gamma=0.01, kernel='sigmoid', max_iter=-1, probability=False,\n",
    "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "svm_classifier.fit(features_train, labels_train)\n",
    "labels_pred = svm_classifier.predict(features_test)\n",
    "print \"---> Gridsearch-tuned SVM classifier:\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\"\n",
    "\n",
    "# Logistic regression tuning: GridSearch\n",
    "scorer = make_scorer(f1_score)\n",
    "parameters = {\"C\":[0.05, 0.5, 1, 10, 10**2,10**5,10**10, 10**20],\n",
    "                    \"tol\":[10**-1, 10**-5, 10**-10],\n",
    "                    \"class_weight\":['auto']}\n",
    "lreg_classifier = LogisticRegression()\n",
    "lreg_tuning = GridSearchCV(lreg_classifier, parameters, scoring=scorer, verbose=1)\n",
    "lreg_tuning.fit(features_train, labels_train)\n",
    "\n",
    "print lreg_tuning.best_estimator_\n",
    "# print lreg_tuning.best_params_\n",
    "print \"\\n\"\n",
    "\n",
    "# Logistic regression: Gridsearch-tuned\n",
    "lreg_classifier = LogisticRegression(C=0.05, class_weight='auto', dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.1, verbose=0)\n",
    "lreg_classifier.fit(features_train, labels_train)\n",
    "labels_pred = lreg_classifier.predict(features_test)\n",
    "print \"---> Logistic regression: Gridsearch tuned\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\"\n",
    "\n",
    "# Naive Bayes: initial Gaussian algorithm (no additional tuning used)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB_classifier = GaussianNB()\n",
    "NB_classifier.fit(features_train, labels_train)\n",
    "labels_pred = NB_classifier.predict(features_test)\n",
    "print \"---> Naive Bayes classifier:\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\"\n",
    "\n",
    "# Naive Bayes multinomal tuning: GridSearch\n",
    "scorer = make_scorer(f1_score)\n",
    "parameters = {\"alpha\":[0.01, 0.1, 0.2, 0.5, 0.8, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 10.0],\n",
    "                    \"fit_prior\":['True', 'False']}\n",
    "mnb_classifier = MultinomialNB()\n",
    "mnb_tuning = GridSearchCV(mnb_classifier, parameters, scoring=scorer, verbose=1)\n",
    "mnb_tuning.fit(features_train, labels_train)\n",
    "\n",
    "print mnb_tuning.best_estimator_\n",
    "# print mnb_tuning.best_params_\n",
    "print \"\\n\"\n",
    "\n",
    "# Naive Bayes multinomial: Gridsearch-tuned\n",
    "mnb_classifier = MultinomialNB(alpha=1.5, fit_prior=False)\n",
    "mnb_classifier.fit(features_train, labels_train)\n",
    "labels_pred = mnb_classifier.predict(features_test)\n",
    "print \"---> Naive Bayes multinomial: Gridsearch tuned\"\n",
    "print classifier_evaluation(labels_test, labels_pred)\n",
    "print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes (Gaussian) validation test --->\n",
      "precision:  0.31746031746\n",
      "recall:  0.388888888889\n",
      "\n",
      "\n",
      "Naive Bayes (multinomial) validation test --->\n",
      "precision:  0.483333333333\n",
      "recall:  0.333333333333\n",
      "\n",
      "\n",
      "Logistic regression validation test --->\n",
      "precision:  0.317841880342\n",
      "recall:  0.666666666667\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "def validation_test(clf):\n",
    "    stratkf = StratifiedKFold(labels, n_folds=3)\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "\n",
    "    for train_x, test_x in stratkf:\n",
    "        features_train = []\n",
    "        labels_train   = []\n",
    "        features_test  = []\n",
    "        labels_test    = []\n",
    "\n",
    "        for i in train_x:\n",
    "            features_train.append(features[i])\n",
    "            labels_train.append(labels[i])\n",
    "        for i in test_x:\n",
    "            features_test.append(features[i])\n",
    "            labels_test.append(labels[i])\n",
    "\n",
    "        # Fit and predict labels with classifier of choice\n",
    "        clf.fit(features_train, labels_train)\n",
    "        labels_pred = clf.predict(features_test)\n",
    "\n",
    "        # Track scores\n",
    "        precision_list.append(precision_score(labels_test, labels_pred))\n",
    "        recall_list.append(recall_score(labels_test, labels_pred))\n",
    "\n",
    "    # Calculate and print average precision and recall across set\n",
    "    print \"precision: \", (sum(precision_list)/3.)\n",
    "    print \"recall: \", (sum(recall_list)/3.)\n",
    "    \n",
    "print \"Naive Bayes (Gaussian) validation test --->\"\n",
    "validation_test(NB_classifier)\n",
    "print \"\\n\"\n",
    "\n",
    "print \"Naive Bayes (multinomial) validation test --->\"\n",
    "validation_test(mnb_classifier)\n",
    "print \"\\n\"\n",
    "\n",
    "print \"Logistic regression validation test --->\"\n",
    "validation_test(lreg_classifier)\n",
    "print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
